{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b6cc5ae",
   "metadata": {},
   "source": [
    "# Fine-Tuning an Embedding Model\n",
    "\n",
    " sentence-transformers framework allows nearly all\n",
    " embedding models to be used as a base for fine-tuning. We can choose an\n",
    " embedding model that was already trained on a large amount of data and\n",
    " fine-tune it for our specific data or purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b416e0",
   "metadata": {},
   "source": [
    "### supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed0dae51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6ea25c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the MNLI dataset\n",
    "train_dataset= load_dataset(\n",
    "    \"glue\", \"mnli\", split= \"train\"\n",
    ").select(range(50000))\n",
    "\n",
    "train_dataset= train_dataset.remove_columns(\"idx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c550745",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an embedding similarity evaluator for stsb\n",
    "val_sts= load_dataset(\n",
    "    \"glue\", \"stsb\", split= \"validation\"\n",
    ")\n",
    "evaluator= EmbeddingSimilarityEvaluator(\n",
    "    sentences1= val_sts[\"sentence1\"],\n",
    "    sentences2= val_sts[\"sentence2\"],\n",
    "    scores=[score/5 for score in val_sts[\"label\"]],\n",
    "    main_similarity= \"cosine\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "331d69bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import losses, SentenceTransformer\n",
    "from sentence_transformers.trainer import SentenceTransformerTrainer\n",
    "from sentence_transformers.training_args import SentenceTransformerTrainingArguments\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fabb7ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SHREYAS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#def model\n",
    "\n",
    "embedding_model= SentenceTransformer(\n",
    "    \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "\n",
    "#loss function\n",
    "train_loss= losses.MultipleNegativesRankingLoss(model=embedding_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19af7d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the training args\n",
    "\n",
    "args= SentenceTransformerTrainingArguments(\n",
    "    output_dir=\"finetuned_embedding_model\",\n",
    "    num_train_epochs= 1,\n",
    "    per_device_eval_batch_size=32,\n",
    "    per_gpu_eval_batch_size=32,\n",
    "    warmup_steps= 100,\n",
    "    fp16=True,\n",
    "    logging_steps= 100,\n",
    "    eval_steps= 100,\n",
    "    report_to=\"none\" # Disable WandB integration\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ccdd0ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be0ba346563e44bd891887b35d536fac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "147f4d2f899e40fea25b15683bbed3fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Column 'hypothesis' is at index 1, whereas a column with this name is usually expected at index 0. Note that the column order can be important for some losses, e.g. MultipleNegativesRankingLoss will always consider the first column as the anchor and the second as the positive, regardless of the dataset column names. Consider renaming the columns to match the expected order, e.g.:\n",
      "dataset = dataset.select_columns(['hypothesis', 'entailment', 'contradiction'])\n",
      "c:\\Users\\SHREYAS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:440: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0757, 'grad_norm': 5.261423110961914, 'learning_rate': 4.9500000000000004e-05, 'epoch': 0.02}\n",
      "{'loss': 0.0661, 'grad_norm': 1.385972499847412, 'learning_rate': 4.9195121951219514e-05, 'epoch': 0.03}\n",
      "{'loss': 0.058, 'grad_norm': 0.7234396934509277, 'learning_rate': 4.8382113821138216e-05, 'epoch': 0.05}\n",
      "{'loss': 0.0541, 'grad_norm': 0.018010197207331657, 'learning_rate': 4.756910569105692e-05, 'epoch': 0.06}\n",
      "{'loss': 0.0423, 'grad_norm': 7.422886371612549, 'learning_rate': 4.675609756097561e-05, 'epoch': 0.08}\n",
      "{'loss': 0.0541, 'grad_norm': 0.20211006700992584, 'learning_rate': 4.594308943089431e-05, 'epoch': 0.1}\n",
      "{'loss': 0.0478, 'grad_norm': 0.0816231444478035, 'learning_rate': 4.513008130081301e-05, 'epoch': 0.11}\n",
      "{'loss': 0.0689, 'grad_norm': 0.10752610117197037, 'learning_rate': 4.431707317073171e-05, 'epoch': 0.13}\n",
      "{'loss': 0.0438, 'grad_norm': 12.70060920715332, 'learning_rate': 4.350406504065041e-05, 'epoch': 0.14}\n",
      "{'loss': 0.0508, 'grad_norm': 2.2857697010040283, 'learning_rate': 4.2691056910569114e-05, 'epoch': 0.16}\n",
      "{'loss': 0.0475, 'grad_norm': 0.09772729128599167, 'learning_rate': 4.18780487804878e-05, 'epoch': 0.18}\n",
      "{'loss': 0.0771, 'grad_norm': 1.8158749341964722, 'learning_rate': 4.1065040650406504e-05, 'epoch': 0.19}\n",
      "{'loss': 0.0446, 'grad_norm': 0.32890865206718445, 'learning_rate': 4.0252032520325205e-05, 'epoch': 0.21}\n",
      "{'loss': 0.0502, 'grad_norm': 0.7939702272415161, 'learning_rate': 3.943902439024391e-05, 'epoch': 0.22}\n",
      "{'loss': 0.0678, 'grad_norm': 0.13298529386520386, 'learning_rate': 3.86260162601626e-05, 'epoch': 0.24}\n",
      "{'loss': 0.0666, 'grad_norm': 0.05955233797430992, 'learning_rate': 3.78130081300813e-05, 'epoch': 0.26}\n",
      "{'loss': 0.0428, 'grad_norm': 0.01962687075138092, 'learning_rate': 3.7e-05, 'epoch': 0.27}\n",
      "{'loss': 0.0511, 'grad_norm': 0.019582558423280716, 'learning_rate': 3.61869918699187e-05, 'epoch': 0.29}\n",
      "{'loss': 0.0555, 'grad_norm': 1.0410468578338623, 'learning_rate': 3.53739837398374e-05, 'epoch': 0.3}\n",
      "{'loss': 0.0582, 'grad_norm': 13.290112495422363, 'learning_rate': 3.4560975609756096e-05, 'epoch': 0.32}\n",
      "{'loss': 0.0473, 'grad_norm': 0.29435983300209045, 'learning_rate': 3.37479674796748e-05, 'epoch': 0.34}\n",
      "{'loss': 0.0533, 'grad_norm': 0.017469681799411774, 'learning_rate': 3.29349593495935e-05, 'epoch': 0.35}\n",
      "{'loss': 0.042, 'grad_norm': 2.2651712894439697, 'learning_rate': 3.2121951219512194e-05, 'epoch': 0.37}\n",
      "{'loss': 0.0265, 'grad_norm': 0.7676198482513428, 'learning_rate': 3.1317073170731706e-05, 'epoch': 0.38}\n",
      "{'loss': 0.056, 'grad_norm': 11.75617504119873, 'learning_rate': 3.0504065040650408e-05, 'epoch': 0.4}\n",
      "{'loss': 0.0383, 'grad_norm': 2.037367105484009, 'learning_rate': 2.969105691056911e-05, 'epoch': 0.42}\n",
      "{'loss': 0.0721, 'grad_norm': 0.31433412432670593, 'learning_rate': 2.8878048780487804e-05, 'epoch': 0.43}\n",
      "{'loss': 0.0404, 'grad_norm': 8.315096855163574, 'learning_rate': 2.8065040650406506e-05, 'epoch': 0.45}\n",
      "{'loss': 0.0305, 'grad_norm': 0.7787613868713379, 'learning_rate': 2.7252032520325204e-05, 'epoch': 0.46}\n",
      "{'loss': 0.0573, 'grad_norm': 0.09847087413072586, 'learning_rate': 2.6439024390243906e-05, 'epoch': 0.48}\n",
      "{'loss': 0.0485, 'grad_norm': 0.08554655313491821, 'learning_rate': 2.5626016260162604e-05, 'epoch': 0.5}\n",
      "{'loss': 0.0339, 'grad_norm': 0.11982079595327377, 'learning_rate': 2.4813008130081302e-05, 'epoch': 0.51}\n",
      "{'loss': 0.03, 'grad_norm': 1.2390234470367432, 'learning_rate': 2.4e-05, 'epoch': 0.53}\n",
      "{'loss': 0.0437, 'grad_norm': 0.35088321566581726, 'learning_rate': 2.31869918699187e-05, 'epoch': 0.54}\n",
      "{'loss': 0.0418, 'grad_norm': 0.7291537523269653, 'learning_rate': 2.23739837398374e-05, 'epoch': 0.56}\n",
      "{'loss': 0.0449, 'grad_norm': 0.07504014670848846, 'learning_rate': 2.15609756097561e-05, 'epoch': 0.58}\n",
      "{'loss': 0.061, 'grad_norm': 16.79652976989746, 'learning_rate': 2.0747967479674797e-05, 'epoch': 0.59}\n",
      "{'loss': 0.0307, 'grad_norm': 1.1669220924377441, 'learning_rate': 1.9934959349593495e-05, 'epoch': 0.61}\n",
      "{'loss': 0.0481, 'grad_norm': 0.016458161175251007, 'learning_rate': 1.9121951219512197e-05, 'epoch': 0.62}\n",
      "{'loss': 0.0321, 'grad_norm': 0.020116755738854408, 'learning_rate': 1.8308943089430895e-05, 'epoch': 0.64}\n",
      "{'loss': 0.0508, 'grad_norm': 0.030799254775047302, 'learning_rate': 1.7495934959349593e-05, 'epoch': 0.66}\n",
      "{'loss': 0.0576, 'grad_norm': 14.169550895690918, 'learning_rate': 1.6682926829268295e-05, 'epoch': 0.67}\n",
      "{'loss': 0.0472, 'grad_norm': 5.706335544586182, 'learning_rate': 1.5869918699186993e-05, 'epoch': 0.69}\n",
      "{'loss': 0.0314, 'grad_norm': 5.982166290283203, 'learning_rate': 1.5056910569105691e-05, 'epoch': 0.7}\n",
      "{'loss': 0.0489, 'grad_norm': 14.014421463012695, 'learning_rate': 1.424390243902439e-05, 'epoch': 0.72}\n",
      "{'loss': 0.0681, 'grad_norm': 0.04220767691731453, 'learning_rate': 1.343089430894309e-05, 'epoch': 0.74}\n",
      "{'loss': 0.0291, 'grad_norm': 2.2669425010681152, 'learning_rate': 1.261788617886179e-05, 'epoch': 0.75}\n",
      "{'loss': 0.0433, 'grad_norm': 0.13532397150993347, 'learning_rate': 1.1804878048780488e-05, 'epoch': 0.77}\n",
      "{'loss': 0.0343, 'grad_norm': 0.01702711172401905, 'learning_rate': 1.0991869918699188e-05, 'epoch': 0.78}\n",
      "{'loss': 0.0339, 'grad_norm': 0.2742979824542999, 'learning_rate': 1.0178861788617888e-05, 'epoch': 0.8}\n",
      "{'loss': 0.0337, 'grad_norm': 0.048391275107860565, 'learning_rate': 9.365853658536586e-06, 'epoch': 0.82}\n",
      "{'loss': 0.0424, 'grad_norm': 7.540362358093262, 'learning_rate': 8.552845528455284e-06, 'epoch': 0.83}\n",
      "{'loss': 0.0401, 'grad_norm': 0.10528117418289185, 'learning_rate': 7.739837398373984e-06, 'epoch': 0.85}\n",
      "{'loss': 0.0418, 'grad_norm': 2.183758497238159, 'learning_rate': 6.934959349593496e-06, 'epoch': 0.86}\n",
      "{'loss': 0.0437, 'grad_norm': 0.751072883605957, 'learning_rate': 6.121951219512195e-06, 'epoch': 0.88}\n",
      "{'loss': 0.0511, 'grad_norm': 3.378614902496338, 'learning_rate': 5.308943089430895e-06, 'epoch': 0.9}\n",
      "{'loss': 0.0381, 'grad_norm': 0.5242347121238708, 'learning_rate': 4.495934959349594e-06, 'epoch': 0.91}\n",
      "{'loss': 0.0397, 'grad_norm': 1.0652966499328613, 'learning_rate': 3.6829268292682928e-06, 'epoch': 0.93}\n",
      "{'loss': 0.0501, 'grad_norm': 1.793900966644287, 'learning_rate': 2.869918699186992e-06, 'epoch': 0.94}\n",
      "{'loss': 0.0454, 'grad_norm': 0.2706109583377838, 'learning_rate': 2.056910569105691e-06, 'epoch': 0.96}\n",
      "{'loss': 0.0389, 'grad_norm': 0.2762218117713928, 'learning_rate': 1.2439024390243904e-06, 'epoch': 0.98}\n",
      "{'loss': 0.0305, 'grad_norm': 2.6171963214874268, 'learning_rate': 4.308943089430894e-07, 'epoch': 0.99}\n",
      "{'train_runtime': 893.9164, 'train_samples_per_second': 55.934, 'train_steps_per_second': 6.992, 'train_loss': 0.04726924160003662, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6250, training_loss=0.04726924160003662, metrics={'train_runtime': 893.9164, 'train_samples_per_second': 55.934, 'train_steps_per_second': 6.992, 'total_flos': 0.0, 'train_loss': 0.04726924160003662, 'epoch': 1.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train model\n",
    "trainer= SentenceTransformerTrainer(\n",
    "    model=embedding_model,\n",
    "    args= args,\n",
    "    train_dataset= train_dataset,\n",
    "    loss= train_loss,\n",
    "    evaluator= evaluator\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "157123fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pearson_cosine': 0.8263247584053353, 'spearman_cosine': 0.8289087350030249}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluate\n",
    "evaluator(embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409e359a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
